---
layout: post
title: 异步编程学习实践（一） -- 异步编程框架了解
categories: 并发与异步编程
tags: CPU 存储 异步编程
---

* content
{:toc}

异步编程学习实践系列，介绍几种异步编程框架，并学习基本原理。



## 1. 背景

[【实践系列】实现一个简单线程池](https://xiaodongq.github.io/2025/03/08/threadpool/) 中，实现了一个基本的线程池，当时的异步编程实现还留了一个TODO。

本篇先学习异步编程的几个框架和基本原理，后续进行编程实践和性能观察对比。

归档在`CPU`或者`存储`目录中貌似都不大合适，新列一个目录：`并发与异步编程`。综合前面追踪Linux存储栈相关的io流程（[学习Linux存储IO栈（四） -- 通用块层](https://xiaodongq.github.io/2024/08/26/linux-io-stack-block/)），并和CPU、内存相关结合起来。

主要学习了解异步编程相关的：**Linux aio**、**io_uring**、**SPDK**、C++的**std::async**、Boost.Asio

参考：

* [[译] Linux 异步 I/O 框架 io_uring：基本原理、程序示例与性能压测（2020）](https://arthurchiao.art/blog/intro-to-io-uring-zh/)
* [spdk doc](https://spdk.io/doc/)
* [cppreference std::async](https://en.cppreference.com/w/cpp/thread/async)
* [Boost.Asio C++ 网络编程](https://mmoaay.gitbooks.io/boost-asio-cpp-network-programming-chinese/content/Chapter1.html)

*说明：本博客作为个人学习实践笔记，可供参考但非系统教程，可能存在错误或遗漏，欢迎指正。若需系统学习，建议参考原链接。*

## 2. 总体说明

借着 [[译] Linux 异步 I/O 框架 io_uring：基本原理、程序示例与性能压测（2020）](https://arthurchiao.art/blog/intro-to-io-uring-zh/) 中的Linux I/O系统调用演进说明，引入异步IO。

Linux I/O系统调用演进：

* 1、基于fd的阻塞式 I/O：`read()`/`write()`
    * fd可指向本地文件（**storage files**）、也可指向网络socket（**network sockets**）
    * 皆为阻塞式系统调用（blocking system calls）
* 2、非阻塞式 I/O：`select()`/`poll()`/`epoll()`
    * 只支持 网络sockets 和 pipes管道
* 3、线程池方式
    * storage I/O，经典解决思路是线程池。主线程将 I/O 分发给 worker 线程，worker中阻塞式读写
    * 问题是 线程上下文切换开销可能非常大
* 4、Direct I/O
    * 数据库软件（database software）有时不想用系统的page cache，而是自己管理缓存，会使用直接IO
    * 设置`O_DIRECT`选项。
        * 之前在 [学习Linux存储IO栈（三） -- eBPF和ftrace跟踪IO写流程](https://xiaodongq.github.io/2024/08/15/linux-write-io-stack/) 中也做过直接IO实验，需要保证申请的空间和系统blocksize对齐（`posix_memalign`），且`write`时长度也须为blocksize整数倍。
        * 现代盘的blocksize一般为4KB，可`blockdev --getbsz /dev/nvme0n1`查看，我PC的盘就是4096（传统盘可能为512字节）
* 5、**异步 IO（AIO）**
    * 市场上有些设备，延迟已经低到和上下文切换一个量级（微秒 us），意味着上下文每切换一次，我们就少一次 `dispatch` I/O 的机会
        * 比如 [Intel Optane](https://pcper.com/2018/12/intels-optane-dc-persistent-memory-dimms-push-latency-closer-to-dram/)
    * 对于block层的调度，`bio`进入`request`（简称`rq`）队列后，设备驱动程序拉取一个rq存到`dispatch`队列，而后封装成`cmd`（比如scsi_cmnd）
        * 可参考 [学习Linux存储IO栈（四） -- 通用块层](https://xiaodongq.github.io/2024/08/26/linux-io-stack-block/) 里梳理的流程
    * Linux 2.6 内核引入了异步 I/O（asynchronous I/O）接口：`Linux AIO`。
    * 基本原理：1）`io_submit()`提交 I/O 请求 2）后续`io_getevents()`检查哪些 events 已经 ready 了
    * 但是，Linux AIO有不少问题：接口设计未考虑扩展性、很多可能的原因会导致阻塞

> 这就是 Linux I/O 的演进历史 —— 只着眼当前，出现一个问题就引入一种设计，而并没有多少前瞻性 —— 直到 `io_uring` 的出现。

## 3. io_uring

io_uring 来自资深内核开发者 [Jens Axboe](https://en.wikipedia.org/wiki/Jens_Axboe) 的想法。（`fio`、`blktrace`作者也是他）



## 4. SPDK

## 5. C++中的异步编程组件

### 5.1. std::async

### 5.2. Boost.Asio

## 6. 小结


## 7. 参考

* [[译] Linux 异步 I/O 框架 io_uring：基本原理、程序示例与性能压测（2020）](https://arthurchiao.art/blog/intro-to-io-uring-zh/)
* [学习Linux存储IO栈（三） -- eBPF和ftrace跟踪IO写流程](https://xiaodongq.github.io/2024/08/15/linux-write-io-stack/)
* [学习Linux存储IO栈（四） -- 通用块层](https://xiaodongq.github.io/2024/08/26/linux-io-stack-block/)
